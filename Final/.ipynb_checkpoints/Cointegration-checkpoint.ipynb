{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import normalize\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data sets\n",
    "market_train_df = pickle.load(open('Market_train',\"rb\"))\n",
    "news_train_df = pickle.load(open('News_train', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data, described more in detail in project report\n",
    "def preprocess_data(mkt_train_df, news_train_df):\n",
    "    mkt_train_df['time'] = mkt_train_df['time'].dt.date\n",
    "    news_train_df['time'] = news_train_df['time'].dt.date\n",
    "    assetCodes = []\n",
    "    index = 0\n",
    "    for x in news_train_df['assetCodes']:\n",
    "        x = x.split(',')[0].split(\"'\")[1]\n",
    "        assetCodes.append(x)\n",
    "    news_train_df['assetCode'] = np.asarray(assetCodes)\n",
    "    irrelevantColumns = ['sourceTimestamp', 'firstCreated', 'sourceId', \n",
    "                         'headline', 'provider', 'subjects', 'audiences',\n",
    "                        'headlineTag', 'marketCommentary', 'assetCodes', 'assetName']\n",
    "    news_train_df.drop(irrelevantColumns, axis=1, inplace=True)\n",
    "    market_train_df.drop(['assetName'], axis=1, inplace=True)\n",
    "    modifiednews = news_train_df.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()\n",
    "    \n",
    "    # join news reports to market data, note many assets will have many days without news data\n",
    "    merged = pd.merge(mkt_train_df, modifiednews, how='left', on=['time', 'assetCode'], copy=False) \n",
    "    merged = merged.fillna(0)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y ranges from -1 to 1, this changes y to range from 0 to 1\n",
    "def normalizeY(ydf):\n",
    "    ydf = (ydf + 1) / 2\n",
    "    return ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataframe into dictionary of dataframes where keys are assetcodes, and values are dataframes of stocks for that key\n",
    "def separateDfByStock(df):\n",
    "    uniqueAssets = df.assetCode.unique()\n",
    "    dfdict = {elem : pd.DataFrame(columns=df.columns.values) for elem in uniqueAssets}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        dfdict[row['assetCode']].append(row)\n",
    "\n",
    "    print(len(dfdict))\n",
    "    return dfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@yashsinha_34838/an-introduction-to-statistical-arbitrage-for-cryptocurrencies-part-1-1a27b3826d50\n",
    "# method to regress prices and get residuals and check for cointegration used from above link\n",
    "def regress_prices(x_data, y_data):\n",
    "    reg = LinearRegression(fit_intercept=True)\n",
    "    reg.fit(x_data.reshape(-1,1), y_data.reshape(-1,1))\n",
    "    r_c, r_i = reg.coef_[0,0], reg.intercept_[0]\n",
    "    return r_c, r_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(x_vals, y_vals, coeffs):\n",
    "    return y_vals - (coeffs[0] * x_vals + coeffs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if 2 codes are cointegrated, using regression and then testing with Augmented Dickey-Fuller test\n",
    "def isCointegrated(code1, code2, sp_dict):\n",
    "    coeffs1 = regress_prices(sp_dict[code1]['open'], sp_dict[code2]['open'])\n",
    "    coeffs2 = regress_prices(sp_dict[code2]['open'], sp_dict[code1]['open'])\n",
    "    resids1 = residuals(sp_dict[code1]['open'], sp_dict[code2]['open'], coeffs1)\n",
    "    resids2 = residuals(sp_dict[code2]['open'], sp_dict[code1]['open'], coeffs2)\n",
    "    adf1 = ts.adfuller(resids1, 2)\n",
    "    adf2 = ts.adfuller(resids2, 2)\n",
    "    return (adf1[1] >= .01 or adf2[1] >= .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds and stops after finding 2 cointegrated pairs\n",
    "def find2CointegratedPairs(sp_dict):\n",
    "    pairs = []\n",
    "    keys = list(sp_dict.keys())\n",
    "    for i in range(len(keys) - 1):\n",
    "        for j in range(1, len(keys)):\n",
    "            if (isCointegrated(keys[i], keys[j], sp_dict)):\n",
    "                pairs.append((keys[i], keys[j]))\n",
    "            if (len(pairs) == 2):\n",
    "                return pairs\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with cointegration, only need to look at prices to find cointegrated pairs, will use rest of data later\n",
    "stocks_and_prices = pd.DataFrame({'assetCode': market_train_df['assetCode'], 'open':market_train_df['open']})\n",
    "sp_dict = separateDfByStock(stocks_and_prices)\n",
    "pairs = find2CointegratedPairs(sp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns new dataframe of rows, where each row now has informations for two stocks where both stocks are cointegrated\n",
    "def joinPairs(X, pair1, pair2):\n",
    "    p1c1, p1c2 = pair1\n",
    "    p2c1, p2c2 = pair2\n",
    "    columns2 = []\n",
    "    for col in X.columns.values:\n",
    "        c2 = col + '_2'\n",
    "        columns2.append(c2)\n",
    "    p1c1df = X[X['assetCode'] == p1c1]\n",
    "    p1c2df = X[X['assetCode'] == p1c2]\n",
    "    p2c1df = X[X['assetcode'] == p2c1]\n",
    "    p2c2df = X[X['assetCode'] == p2c2]\n",
    "    joinedcolumns = X.columns.values + columns2\n",
    "    joinedp1df = pd.DataFrame(columns=joinedcolumns)\n",
    "    joinedp2df = pd.DataFrame(columns=joinedcolumns)\n",
    "    for col in joinedp1df.columns.values:\n",
    "        if (col in columns2):\n",
    "            joinedp1df[col] = p1c2df[col[:-2]]\n",
    "            joinedp2df[col] = p2c2df[col[:-2]]\n",
    "        else:\n",
    "            joinedp1df[col] = p1c1df[col]\n",
    "            joinedp2df[col] = p2c1df[col]\n",
    "    joinedDf = joinedp1df.append(joinedp2df)\n",
    "    return joinedDf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data, and use pairs found earlier to get the new dataframe\n",
    "X = preprocess_data(market_data, news_data)\n",
    "X = X[X['returnsOpenNextMktres10'] >= -1]\n",
    "X = X[X['returnsOpenNextMktres10'] <= 1]\n",
    "X['returnsOpenNextMktres10'] = normalize(X['returnsOpenNextMktres10'])\n",
    "joinedDf = joinPairs(X, pairs[0], pairs[1])\n",
    "\n",
    "y1 = joinedDf['returnsOpenNextMktres10']\n",
    "y2 = joinedDf['returnsOpenNextMktres10_2']\n",
    "# drop y values and other irrelavant columns\n",
    "joinedDf.drop(['returnsOpenNextMktres10', 'returnsOpenNextMktres10_2', 'time', 'time_2', 'assetCode', 'assetCode_2'])\n",
    "y = pd.DataFrame({'y1': y1, 'y2':y2 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ANN model\n",
    "layers = []\n",
    "layers.append(keras.layers.Flatten(input_shape=(len(joinedDf.columns.values),)))\n",
    "\n",
    "for x in range(3):\n",
    "    layers.append(keras.layers.Dense(15, activation=tf.nn.relu, use_bias=True))\n",
    "\n",
    "layers.append(keras.layers.Dense(2, activation=tf.nn.sigmoid))\n",
    "model = keras.Sequential(layers)\n",
    "sgd = keras.optimizers.SGD(lr=.3)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['accuracy'])\n",
    "# train with model and validation_split to be used as testing data\n",
    "model.fit(joinedDf, y, batch_size=1000000, epochs=10, validation_split=.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
