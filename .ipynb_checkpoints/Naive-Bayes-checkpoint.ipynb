{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFiles():\n",
    "    market_df = pickle.load(open('Market_train',\"rb\"))\n",
    "    news_df = pickle.load(open(\"News_train\", \"rb\"))\n",
    "    print('Finished loading datafiles!')\n",
    "    return market_df, news_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(mkt_df, news_df):\n",
    "    mkt_df['time'] = pd.to_datetime(mkt_df['time'])\n",
    "    news_df['time'] = pd.to_datetime(news_df['time'])\n",
    "    mkt_df['time'] = mkt_df['time'].dt.date\n",
    "    news_df['time'] = news_df['time'].dt.date\n",
    "    assetCodes = []\n",
    "    index = 0\n",
    "    for x in news_df['assetCodes']:\n",
    "        x = x.split(',')[0].split(\"'\")[1]\n",
    "        assetCodes.append(x)\n",
    "    news_df['assetCode'] = np.asarray(assetCodes)\n",
    "    irrelevantColumns = ['sourceTimestamp', 'firstCreated', 'sourceId', \n",
    "                         'headline', 'provider', 'subjects', 'audiences',\n",
    "                        'headlineTag', 'marketCommentary', 'assetCodes', 'assetName']\n",
    "    news_df.drop(irrelevantColumns, axis=1, inplace=True)\n",
    "    mkt_df.drop(['assetName'], axis=1, inplace=True)\n",
    "    modifiednews = news_df.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()\n",
    "    \n",
    "    # join news reports to market data, note many assets will have many days without news data\n",
    "    merged = pd.merge(mkt_df, modifiednews, how='left', on=['time', 'assetCode'], copy=False) \n",
    "    merged = merged.fillna(0)\n",
    "    print('Finished preprocessing data!')\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading datafiles!\n"
     ]
    }
   ],
   "source": [
    "market_data, news_data = loadDataFiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing data!\n"
     ]
    }
   ],
   "source": [
    "X = preprocess_data(market_data, news_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994287\n"
     ]
    }
   ],
   "source": [
    "X = X[X['returnsOpenNextMktres10'] >= -1]\n",
    "X = X[X['returnsOpenNextMktres10'] <= 1]\n",
    "y = X['returnsOpenNextMktres10']\n",
    "print(len(y[y < 0]))\n",
    "X.drop(['returnsOpenNextMktres10'], axis=1, inplace=True)\n",
    "assetCodesAndTime = X.iloc[:, :2]\n",
    "X = X.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(df):\n",
    "    for column in df:\n",
    "        colmin = np.amin(df[column])\n",
    "        colmax = np.amax(df[column])\n",
    "        df[column] = (df[column] - colmin) / (colmax - colmin)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = regularize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, model_name):\n",
    "    model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(filename):\n",
    "    model = load_model(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createBiaser(X,y):\n",
    "#     negCount = 0.0 # total negatives in the dataset\n",
    "#     posCount = 0.0 # total positives in the dataset\n",
    "#     totalPosScore = 0.0 #cumulative score of all fields that has been classified as positive in the entire dataset\n",
    "#     totalNegScore = 0.0 # same for negative\n",
    "#     isPos = False \n",
    "#     isNeg = False \n",
    "#     positiveScores = defaultdict(float) # cumulative score for each field that has been classified as positive stored in a dict\n",
    "#     negativeScores = defaultdict(float) # same for negative\n",
    "    \n",
    "#     # initializing data\n",
    "#     for index, row in y.iteritems():\n",
    "#         if y[index] < 0:\n",
    "#             negCount += 1\n",
    "#             isNeg = True\n",
    "#             isPos = False\n",
    "#         else:\n",
    "#             posCount += 1\n",
    "#             isNeg = False\n",
    "#             isPos = True\n",
    "            \n",
    "#         for feature in X.iloc[[index]]:\n",
    "# #             print(X.iloc[index][feature])\n",
    "#             if isPos == True:\n",
    "#                 positiveScores[feature] += X.iloc[index][feature]\n",
    "#                 totalPosScore += X.iloc[index][feature]\n",
    "#             elif isNeg == True:\n",
    "#                 negativeScores[feature] += X.iloc[index][feature]\n",
    "#                 totalNegScore += X.iloc[index][feature]\n",
    "          \n",
    "#     return negCount, posCount, totalPosScore, totalNegScore, positiveScores, negativeScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = regularize(X)\n",
    "# def printData():\n",
    "#     negCount, posCount, totalPosScore, totalNegScore, positiveScores, negativeScores = createBiaser(X[:1000],y[:1000])\n",
    "#     print(\"Total Negatives: \", negCount)\n",
    "#     print(\"Total Positives: \", posCount)\n",
    "#     print(\"Total Positive Score: \", totalPosScore)\n",
    "#     print(\"Total Negative Score: \", totalNegScore)\n",
    "#     for feature in X.iloc[[1]]:\n",
    "#         print(\"Feature: \", feature)\n",
    "#         print(\"positiveScore: \", positiveScores[feature])\n",
    "#         print(\"negativeScore: \", negativeScores[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(X, y, split):\n",
    "    index = int(split*len(y.index))\n",
    "    y_train, y_test = np.split(y, [index])\n",
    "    X_train, X_test = X.iloc[:index, :], X.iloc[index:, :]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374968\n",
      "619319\n"
     ]
    }
   ],
   "source": [
    "X = regularize(X)\n",
    "X_train, y_train, X_test, y_test = splitDataset(X, y, 0.7)\n",
    "print(len(y_train[y_train < 0]))\n",
    "print(len(y_test[y_test < 0]))\n",
    "# negCount, posCount, totalPosScore, totalNegScore, positiveScores, negativeScores = createBiaser(X_train,y_train)\n",
    "# loss = classify(negCount, posCount, totalPosScore, totalNegScore, positiveScores, negativeScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify(negCount, posCount, totalPosScore, totalNegScore, PositiveScore, negativeScore):\n",
    "#     loss = []\n",
    "#     totalPosScore = 0.0\n",
    "#     totalNegScore = 0.0\n",
    "#     priorPos = math.log(posCount) - math.log(posCount + negCount)\n",
    "#     priorNeg = math.log(negCount) - math.log(posCount + negCount)\n",
    "\n",
    "#     for feature in X_test.iloc[[1]]:\n",
    "#         if feature in positiveScores:\n",
    "#             if positiveScores[feature] != 0 and totalPosScore != 0:\n",
    "#                 posteriorPos = math.log(positiveScores[feature]) - math.log(totalPosScore)\n",
    "#             else:\n",
    "#                 posteriorPos = 0.0\n",
    "#         totalPosScore += posteriorPos\n",
    "\n",
    "#         if feature in negativeScores:\n",
    "#             if negativeScores[feature] != 0 and totalNegScore != 0:\n",
    "#                 posteriorNeg = math.log(negativeScores[feature]) - math.log(totalNegScore)\n",
    "#             else:\n",
    "#                 posteriorNeg = 0.0\n",
    "#         totalNegScore += posteriorNeg\n",
    "\n",
    "#     totalPosScore += priorPos\n",
    "#     totalNegScore += priorNeg\n",
    "#     for val in y_test:\n",
    "#         if totalPosScore > totalNegScore:\n",
    "#             loss.append(val - totalPosScore)\n",
    "#         else:\n",
    "#             loss.append(val - totalNegScore)\n",
    "        \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = classify(negCount, posCount, totalPosScore, totalNegScore, positiveScores, negativeScores)\n",
    "# # for item in loss:\n",
    "# #     print(item)\n",
    "\n",
    "# mean = sum(loss) / float(len(loss))\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classwify(y):\n",
    "\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 2\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = np.copy(y_train)\n",
    "y_test_new = np.copy(y_test)\n",
    "y_train_new = classwify(y_train)\n",
    "y_test_new = classwify(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([-0.99871791, -0.99814278, -0.99382127, ...,  0.99264803,\n        0.99424496,  0.99440021]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-85f02d7bc059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m--> 192\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;31m# This is the first call to partial_fit:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# initialize various cumulative counters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m_check_partial_fit_first_call\u001b[0;34m(clf, classes)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# This is the first call to partial_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([-0.99871791, -0.99814278, -0.99382127, ...,  0.99264803,\n        0.99424496,  0.99440021]),)"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train_new)\n",
    "probs = clf.score(X_test, y_test_new)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
