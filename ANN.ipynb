{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFiles():\n",
    "    market_df = pickle.load(open('Market_train',\"rb\"))\n",
    "    news_df = pickle.load(open(\"News_train\", \"rb\"))\n",
    "    print('Finished loading datafiles!')\n",
    "    return market_df, news_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(mkt_df, news_df):\n",
    "    mkt_df['time'] = pd.to_datetime(mkt_df['time'])\n",
    "    news_df['time'] = pd.to_datetime(news_df['time'])\n",
    "    mkt_df['time'] = mkt_df['time'].dt.date\n",
    "    news_df['time'] = news_df['time'].dt.date\n",
    "    assetCodes = []\n",
    "    index = 0\n",
    "    for x in news_df['assetCodes']:\n",
    "        x = x.split(',')[0].split(\"'\")[1]\n",
    "        assetCodes.append(x)\n",
    "    news_df['assetCode'] = np.asarray(assetCodes)\n",
    "    irrelevantColumns = ['sourceTimestamp', 'firstCreated', 'sourceId', \n",
    "                         'headline', 'provider', 'subjects', 'audiences',\n",
    "                        'headlineTag', 'marketCommentary', 'assetCodes', 'assetName']\n",
    "    news_df.drop(irrelevantColumns, axis=1, inplace=True)\n",
    "    mkt_df.drop(['assetName'], axis=1, inplace=True)\n",
    "    modifiednews = news_df.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()\n",
    "    \n",
    "    # join news reports to market data, note many assets will have many days without news data\n",
    "    merged = pd.merge(mkt_df, modifiednews, how='left', on=['time', 'assetCode'], copy=False) \n",
    "    merged = merged.fillna(0)\n",
    "    print('Finished preprocessing data!')\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading datafiles!\n"
     ]
    }
   ],
   "source": [
    "market_data, news_data = loadDataFiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing data!\n"
     ]
    }
   ],
   "source": [
    "X = preprocess_data(market_data, news_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeY(ydf):\n",
    "    ydf = (ydf + 1) / 2\n",
    "    return ydf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['returnsOpenNextMktres10'] >= -1]\n",
    "X = X[X['returnsOpenNextMktres10'] <= 1]\n",
    "\n",
    "y = X['returnsOpenNextMktres10']\n",
    "\n",
    "X.drop(['returnsOpenNextMktres10'], axis=1, inplace=True)\n",
    "y = normalizeY(y)\n",
    "assetCodesAndTime = X.iloc[:, :2]\n",
    "X = X.iloc[:, 2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNNModel(numhiddenlayers=2, nodes=4): # returns NN given hidden layers and nodes\n",
    "    layers = []\n",
    "    layers.append(keras.layers.Flatten(input_shape=(35,)))\n",
    "\n",
    "    for x in range(numhiddenlayers):\n",
    "        layers.append(keras.layers.Dense(nodes, activation=tf.nn.relu, use_bias=True))\n",
    "\n",
    "    layers.append(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    model = keras.Sequential(layers)\n",
    "    sgd = keras.optimizers.SGD(lr=.3)\n",
    "    model.compile(optimizer=sgd,\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinearRegressionModel():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=200, input_dim=35))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(units=45))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "              optimizer='sgd')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(df):\n",
    "    for column in df:\n",
    "        colmin = np.amin(df[column])\n",
    "        colmax = np.amax(df[column])\n",
    "        df[column] = (df[column] - colmin) / (colmax - colmin)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(X, y, split):\n",
    "    index = int(split*len(y.index))\n",
    "    y_train, y_test = np.split(y, [index])\n",
    "    X_train, X_test = X.iloc[:index, :], X.iloc[index:, :]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = regularize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, model_name):\n",
    "    model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(filename):\n",
    "    model = load_model(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1221660 samples, validate on 2850543 samples\n",
      "Epoch 1/1\n",
      "1221660/1221660 [==============================] - 6s 5us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x137c46d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmodel = getNNModel(3, 15)\n",
    "nnmodel.fit(X, y, epochs=1, verbose=1, batch_size=100000, validation_split=.7)\n",
    "# results = nnmodel.evaluate(X_test, y_test)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossMatrix(X, y):\n",
    "    layers = [3, 4, 5]\n",
    "    nodes = [10, 15, 20]\n",
    "    lossmatrix = []\n",
    "#     X_train, y_train, X_test, y_test = splitDataset(X, y, .7)\n",
    "#     for layer in layers:\n",
    "#         lossforlayer = []\n",
    "#         for node in nodes:\n",
    "#             nnmodel2 = getNNModel(layer, node)\n",
    "#             nnmodel2.fit(X_train , y_train, epochs=1, verbose=1, batch_size=1000000)\n",
    "#             loss, acc = nnmodel2.evaluate(X_test, y_test)\n",
    "#             lossforlayer.append(loss)\n",
    "#         lossmatrix.append(lossforlayer)\n",
    "    for x in lossmatrix:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4072203\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 7s 2us/step - loss: 0.0246 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 21s 18us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 6s 2us/step - loss: 0.0254 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 25s 20us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 9s 3us/step - loss: 0.0247 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 22s 18us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 8s 3us/step - loss: 0.0238 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 28s 23us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 7s 2us/step - loss: 0.0301 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 23s 19us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0246 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 23s 19us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 7s 2us/step - loss: 0.0249 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 26s 21us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 9s 3us/step - loss: 0.0243 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 29s 24us/step\n",
      "Epoch 1/1\n",
      "2850542/2850542 [==============================] - 10s 3us/step - loss: 0.0265 - acc: 0.0000e+00\n",
      "1221661/1221661 [==============================] - 29s 24us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lossmaxtrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-221b881e6e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlossMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-0b013f96b1ad>\u001b[0m in \u001b[0;36mlossMatrix\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mlossforlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlossmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossforlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlossmaxtrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lossmaxtrix' is not defined"
     ]
    }
   ],
   "source": [
    "lossMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2850542 samples, validate on 1221661 samples\n",
      "Epoch 1/10\n",
      "2850542/2850542 [==============================] - 16s 5us/step - loss: 0.4275 - val_loss: 0.3473\n",
      "Epoch 2/10\n",
      "2850542/2850542 [==============================] - 18s 6us/step - loss: 0.3199 - val_loss: 0.2457\n",
      "Epoch 3/10\n",
      "2850542/2850542 [==============================] - 13s 5us/step - loss: 0.2197 - val_loss: 0.1467\n",
      "Epoch 4/10\n",
      "2850542/2850542 [==============================] - 14s 5us/step - loss: 0.1229 - val_loss: 0.0646\n",
      "Epoch 5/10\n",
      "2850542/2850542 [==============================] - 14s 5us/step - loss: 0.0526 - val_loss: 0.0343\n",
      "Epoch 6/10\n",
      "2850542/2850542 [==============================] - 13s 5us/step - loss: 0.0345 - val_loss: 0.0325\n",
      "Epoch 7/10\n",
      "2850542/2850542 [==============================] - 14s 5us/step - loss: 0.0332 - val_loss: 0.0315\n",
      "Epoch 8/10\n",
      "2850542/2850542 [==============================] - 19s 7us/step - loss: 0.0325 - val_loss: 0.0307\n",
      "Epoch 9/10\n",
      "2850542/2850542 [==============================] - 20s 7us/step - loss: 0.0319 - val_loss: 0.0301\n",
      "Epoch 10/10\n",
      "2850542/2850542 [==============================] - 18s 6us/step - loss: 0.0313 - val_loss: 0.0295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1234c9e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel = getLinearRegressionModel()\n",
    "lrmodel.fit(X,y, batch_size=1000000, epochs=10, validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bfabc2cb93c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# xplot = list(range(len(y_test)))\n",
    "# plt.plot(xplot, lrpredictions)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(xplot, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2850542 samples, validate on 1221661 samples\n",
      "Epoch 1/10\n",
      "2850542/2850542 [==============================] - 8s 3us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2850542/2850542 [==============================] - 8s 3us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2850542/2850542 [==============================] - 7s 3us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x125ea1c88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnnmodel = getNNModel(3,15)\n",
    "hist = keras.callbacks.History()\n",
    "num_epochs = 10\n",
    "newnnmodel.fit(X, y, epochs=num_epochs, batch_size=1000000, callbacks=[hist], validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
